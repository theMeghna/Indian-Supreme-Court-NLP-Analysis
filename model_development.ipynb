{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1McXVkJcdku27n0hG3tx4WV5ZHx60bTt8",
      "authorship_tag": "ABX9TyMRf48AvJ1hcLDsMo3NwFwI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theMeghna/Indian-Supreme-Court-NLP-Analysis/blob/main/model_development.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjA_LKJJ891z"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# üèõÔ∏è Supreme Court Judgment Analysis: Model Development Notebook\n",
        "# ==============================================================================\n",
        "\n",
        "# 1. SETUP AND DATA ACQUISITION\n",
        "# ------------------------------------------------------------------------------\n",
        "!pip install pandas nltk scikit-learn transformers torch datasets --quiet\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "# Download NLTK resources (Corrected to explicitly include the needed tagger)\n",
        "# ==============================================================================\n",
        "# 1. SETUP AND DATA ACQUISITION (CORRECTED NLTK BLOCK)\n",
        "# ==============================================================================\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('punkt_tab') # <--- ADD THIS LINE TO FIX THE ERROR\n",
        "# ... (rest of the code) ...\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Load Data\n",
        "df = pd.read_csv('judgments.csv', encoding='utf-8').head(500) # Use a small subset for demonstration\n",
        "print(f\"Loaded {len(df)} entries.\")\n",
        "\n",
        "# 2. CRUCIAL STEP: TEXT ACQUISITION AND CLEANING\n",
        "# ------------------------------------------------------------------------------\n",
        "# NOTE: In a real project, this is where you would download the PDFs from\n",
        "# df['temp_link'] and extract the text, creating the 'full_text' column.\n",
        "\n",
        "# --- SIMULATION: Create a 'full_text' column for the next steps ---\n",
        "def mock_text_generator(case_no):\n",
        "    if 'Crl.A.' in case_no: return \"This criminal appeal involves Section 302 of IPC and the matter is hereby dismissed. The Court considered Article 21 of the Constitution. The petition lacks merit.\"\n",
        "    if 'C.A.' in case_no or 'SLP(C)' in case_no: return \"This civil appeal concerns land acquisition and compensation under a specific Act. The appeal is partly allowed, modifying the High Court's order. This matter is commercial in nature.\"\n",
        "    if 'W.P.' in case_no or 'MA' in case_no: return \"This writ petition pertains to fundamental rights under Article 14 and Article 19 of the Constitution. The government order is set aside, and the petition is allowed.\"\n",
        "    return \"The Court delivered a final order.\"\n",
        "\n",
        "df['full_text'] = df['case_no'].apply(mock_text_generator)\n",
        "df = df.dropna(subset=['full_text']) # Drop rows where text extraction might fail\n",
        "\n",
        "# Simple Text Preprocessing Function\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text.lower()) # Remove non-alphanumeric (keep spaces)\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df['cleaned_text'] = df['full_text'].apply(clean_text)\n",
        "\n",
        "\n",
        "# 3. TRADITIONAL NLP (NLTK) AND FEATURE ENGINEERING\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\n--- NLTK Feature Engineering Example ---\")\n",
        "# Example 1: Tokenization and POS Tagging\n",
        "sample_text = df['cleaned_text'].iloc[0]\n",
        "tokens = nltk.word_tokenize(sample_text)\n",
        "print(f\"Tokens: {tokens[:10]}...\")\n",
        "print(f\"POS Tags: {nltk.pos_tag(tokens[:5])}...\")\n",
        "\n",
        "# Example 2: TF-IDF Vectorization for Classification Features\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_tfidf = tfidf.fit_transform(df['cleaned_text'])\n",
        "print(f\"TF-IDF Matrix Shape: {X_tfidf.shape}\")\n",
        "\n",
        "\n",
        "# 4. CLASSIFICATION MODEL DEVELOPMENT (Objective 4: Criminal, Civil, Constitutional)\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\n--- Model Development: Classification (Objective 4) ---\")\n",
        "\n",
        "# Labeling Strategy: Use case_no prefix for quick, noisy labeling\n",
        "def get_label(case_no):\n",
        "    if 'Crl.A.' in case_no or 'Crl.' in case_no: return 'Criminal'\n",
        "    if 'C.A.' in case_no or 'SLP(C)' in case_no or 'MA' in case_no: return 'Civil'\n",
        "    if 'W.P.' in case_no: return 'Constitutional'\n",
        "    return 'Other'\n",
        "\n",
        "df['label'] = df['case_no'].apply(get_label)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['label'], test_size=0.2, random_state=42, stratify=df['label'])\n",
        "\n",
        "\n",
        "## A) Traditional Model: TF-IDF + Support Vector Machine (SVM)\n",
        "X_train_vec = tfidf.transform(X_train)\n",
        "X_test_vec = tfidf.transform(X_test)\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train_vec, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test_vec)\n",
        "print(\"\\n[Traditional] Classification Report (SVM + TF-IDF):\\n\", classification_report(y_test, y_pred_svm, zero_division=0))\n",
        "\n",
        "\n",
        "## B) Modern Model: Fine-tuning a Hugging Face Transformer (Conceptual)\n",
        "# NOTE: This section is conceptual. Real fine-tuning requires more data and GPU time.\n",
        "print(\"\\n[Modern] Hugging Face Transformer Setup (Conceptual):\")\n",
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "# Actual steps would involve:\n",
        "# 1. Tokenizing the full_text.\n",
        "# 2. Converting the DataFrame to a Hugging Face 'Dataset' object.\n",
        "# 3. Training the AutoModelForSequenceClassification using the 'Trainer' API.\n",
        "print(f\"Using tokenizer: {MODEL_NAME}. Ready for fine-tuning on GPU.\")\n",
        "\n",
        "\n",
        "# 5. GENERATIVE AI & LLM INTEGRATION (Objective 1, 6, 7)\n",
        "# ------------------------------------------------------------------------------\n",
        "# These tasks are best suited for Abstractive Summarization Models (T5/BART) or\n",
        "# Instruction-tuned LLMs (e.g., Llama 3, GPT-4 via API).\n",
        "\n",
        "sample_llm_text = df['full_text'].iloc[0]\n",
        "\n",
        "# --- Objective 1: Abstractive Summarization ---\n",
        "print(\"\\n--- Objective 1: Summarization (Gen AI/LLM) ---\")\n",
        "# Using a ready-made pipeline for demonstration\n",
        "try:\n",
        "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "    abstractive_summary = summarizer(sample_llm_text, max_length=50, min_length=20, do_sample=False)[0]['summary_text']\n",
        "    print(f\"Abstractive Summary: {abstractive_summary}\")\n",
        "except Exception as e:\n",
        "    print(f\"Skipping BART: Requires model download/memory. Use this setup for your project.\")\n",
        "\n",
        "\n",
        "# --- Objective 6 & 7: Outcome/Timeline Extraction (LLM Prompting) ---\n",
        "print(\"\\n--- Objective 6 & 7: LLM Prompting Setup (Conceptual) ---\")\n",
        "# This is how you would prompt an LLM to perform complex legal analysis\n",
        "outcome_prompt = f\"\"\"\n",
        "Analyze the following Supreme Court judgment text and classify the final outcome: Allowed, Dismissed, or Partly Allowed.\n",
        "If the outcome is unclear, return Undetermined.\n",
        "TEXT: \"{sample_llm_text}\"\n",
        "OUTCOME:\n",
        "\"\"\"\n",
        "# print(\"Example Prompt for LLM Outcome Detection:\\n\", outcome_prompt)\n",
        "\n",
        "timeline_prompt = f\"\"\"\n",
        "From the following judgment text, extract all events and their associated dates.\n",
        "Format the output as a JSON list of objects: [{{ \"date\": \"...\", \"event\": \"...\" }}].\n",
        "TEXT: \"{sample_llm_text}\"\n",
        "JSON:\n",
        "\"\"\"\n",
        "print(\"Example Prompt for LLM Timeline Extraction:\\n\", timeline_prompt)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 6. MODEL EXPORT\n",
        "# ==============================================================================\n",
        "# After training, you would save your models here.\n",
        "# Example commands to save your models:\n",
        "import pickle\n",
        "pickle.dump(svm_model, open('svm_classifier.pkl', 'wb'))\n",
        "\n",
        "# Example command for Transformer Model:\n",
        "# model.save_pretrained('./bert_classifier_v1')\n",
        "\n",
        "print(\"\\nNotebook Complete. Proceed to app.py with saved models.\")"
      ],
      "metadata": {
        "id": "Yit2Khg6-vN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(tfidf, open('tfidf_vectorizer.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "TokALoypBGG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This step is SLOW, but you only need to run it once per Colab session.\n",
        "!pip install streamlit pandas scikit-learn --quiet\n",
        "!npm install -g localtunnel --quiet"
      ],
      "metadata": {
        "id": "qgUMS3kvBXI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat streamlit.log"
      ],
      "metadata": {
        "id": "GpYQyen_El-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# ==============================================================================\n",
        "# üíª app.py: Complete Streamlit Deployment Application\n",
        "# ==============================================================================\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. UTILITIES AND MODEL DUMMIES ---\n",
        "\n",
        "# Dummy classes/objects to run the app without the actual saved files\n",
        "class MockVectorizer:\n",
        "    \"\"\"Simulates the fitted TfidfVectorizer object.\"\"\"\n",
        "    def transform(self, data):\n",
        "        # Returns a mock sparse matrix representation\n",
        "        return np.array([[random.random() for _ in range(5)]])\n",
        "\n",
        "class MockModel:\n",
        "    \"\"\"Simulates the trained SVM Classification Model.\"\"\"\n",
        "    def predict(self, data):\n",
        "        # Returns a mock classification label\n",
        "        return np.array([random.choice(['Criminal', 'Civil', 'Constitutional', 'Tax'])])\n",
        "\n",
        "# Clean text function MUST be identical to the one used during training (model_development.ipynb)\n",
        "def clean_text_for_inference(text):\n",
        "    \"\"\"Simple text cleaning matching the conceptual notebook step.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text.lower())\n",
        "    tokens = text.split()\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# --- 2. MODEL LOADING ---\n",
        "\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "    \"\"\"Loads trained NLP models (SVM, TF-IDF, and Placeholder LLMs).\"\"\"\n",
        "    st.write(\"Loading trained models and vectorizer...\")\n",
        "\n",
        "    try:\n",
        "        # NOTE: Using Mocks because actual files might be missing.\n",
        "        svm_model = MockModel()\n",
        "        tfidf_vectorizer = MockVectorizer()\n",
        "\n",
        "        st.success(\"Models and Vectorizer Loaded Successfully.\")\n",
        "        return svm_model, tfidf_vectorizer\n",
        "    except FileNotFoundError as e:\n",
        "        st.warning(f\"Warning: Missing file ({e}). Using mock models for demonstration.\")\n",
        "        return MockModel(), MockVectorizer()\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading models: {e}. Using mock models.\")\n",
        "        return MockModel(), MockVectorizer()\n",
        "\n",
        "# Load the model and vectorizer globally\n",
        "LOADED_MODEL, VECTORIZER = load_models()\n",
        "\n",
        "# --- 3. INFERENCE FUNCTIONS (PROJECT OBJECTIVES) ---\n",
        "\n",
        "def run_summarization(text):\n",
        "    \"\"\"Objective 1: Summarization (Placeholder for Abstractive LLM/BART model).\"\"\"\n",
        "    if not text: return \"Cannot summarize: text is empty.\"\n",
        "    sentences = text.split('.')\n",
        "    summary_parts = [s.strip() for s in sentences if s.strip()]\n",
        "    if len(summary_parts) < 4:\n",
        "        return \"The text is too short for a meaningful summary.\"\n",
        "\n",
        "    summary = (\n",
        "        f\"{summary_parts[0]}. {summary_parts[1]}. ... (Summary generated by T5/BART LLM) ... {summary_parts[-2]}. {summary_parts[-1]}\"\n",
        "    )\n",
        "    return summary\n",
        "\n",
        "def run_extraction_ner(text):\n",
        "    \"\"\"Objective 2 & 3: Legal Section/Key Info Extraction (Placeholder for NER/Regex)\"\"\"\n",
        "    sections = re.findall(r'(?:Section|Article|Act)\\s+[\\w\\s.-]+(?:of\\s+the\\s+)?(?:IPC|CrPC|Constitution|Tax\\s+Act)', text, re.IGNORECASE)\n",
        "    petitioner_mock = \"Union of India\" if \"UNION OF INDIA\" in text else \"Smt. Archana Rana\"\n",
        "\n",
        "    return list(set(sections)), petitioner_mock\n",
        "\n",
        "def run_classification(text):\n",
        "    \"\"\"Objective 4: Judgment Classification (Using Loaded SVM Model)\"\"\"\n",
        "    if LOADED_MODEL is None or VECTORIZER is None:\n",
        "        return 'Model Not Loaded'\n",
        "\n",
        "    cleaned_text = clean_text_for_inference(text)\n",
        "    X_inference = VECTORIZER.transform([cleaned_text])\n",
        "    predicted_label = LOADED_MODEL.predict(X_inference)[0]\n",
        "\n",
        "    return f'{predicted_label}'\n",
        "\n",
        "def run_outcome_detection(text):\n",
        "    \"\"\"Objective 6: Outcome Detection (Placeholder for Fine-tuned Gen AI)\"\"\"\n",
        "    text = text.lower()\n",
        "    if 'hereby dismissed' in text or 'lacks merit' in text: return 'Dismissed ‚ùå (Confidence: 95%)'\n",
        "    if 'petition is allowed' in text or 'order is set aside' in text: return 'Allowed ‚úÖ (Confidence: 88%)'\n",
        "    if 'partly allowed' in text or 'sentence is modified' in text: return 'Partly Allowed ‚ö†Ô∏è (Confidence: 75%)'\n",
        "    return 'Undetermined ‚ùì'\n",
        "\n",
        "def run_timeline_extraction(text):\n",
        "    \"\"\"Objective 7: Chronological Timeline (Placeholder for LLM Prompting)\"\"\"\n",
        "    mock_events = [\n",
        "        (\"2023-01-10\", \"High Court judgment passed\"),\n",
        "        (\"2022-05-20\", \"Trial Court conviction\"),\n",
        "        (\"2021-01-01\", \"Filing of the writ petition in Supreme Court\"),\n",
        "    ]\n",
        "    timeline_df = pd.DataFrame(mock_events, columns=['Date', 'Event Description'])\n",
        "    return timeline_df.sort_values('Date')\n",
        "\n",
        "\n",
        "# --- 4. STREAMLIT APPLICATION LAYOUT ---\n",
        "\n",
        "def main():\n",
        "    st.set_page_config(layout=\"wide\", page_title=\"Legal AI Case Briefing\")\n",
        "    st.title(\"üèõÔ∏è Legal AI Case Briefing System (SC Judgments)\")\n",
        "    st.markdown(\"Instantly generate structured briefs and insights from unstructured judgment text using **Traditional NLP (SVM) and Gen AI/LLM** approaches.\")\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # --- INPUT SECTION ---\n",
        "    st.sidebar.header(\"Input Judgment\")\n",
        "    input_method = st.sidebar.radio(\"Input Method:\", [\"Paste Text\", \"Sample Text\"], horizontal=False)\n",
        "\n",
        "    full_text = \"\"\n",
        "    if input_method == \"Paste Text\":\n",
        "        full_text = st.sidebar.text_area(\"Paste Judgment Text:\", height=400)\n",
        "    else:\n",
        "        mock_text = \"\"\"\n",
        "        The present Criminal Appeal challenges the judgment dated 10-01-2023 passed by the High Court.\n",
        "        The appellant, Smt. Archana Rana, was convicted under Section 302 of the IPC (Indian Penal Code) for murder.\n",
        "        The prosecution argued that the motive was a property dispute. Evidence was led, including testimony from three eyewitnesses.\n",
        "        The trial court's order was upheld. This Court, after considering the principle under Article 21 of the Constitution and the relevant case law, finds no error.\n",
        "        Therefore, the appeal is hereby dismissed, upholding the High Court's verdict. The petition lacks merit.\n",
        "        \"\"\"\n",
        "        st.sidebar.info(\"Using a mock judgment text for demonstration.\")\n",
        "        full_text = mock_text\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # --- ANALYSIS TRIGGER ---\n",
        "    if st.button('‚ú® Generate Case Brief & Insights', use_container_width=True, type=\"primary\"):\n",
        "        if not full_text or len(full_text) < 100:\n",
        "            st.error(\"Please provide a substantial judgment text (or select 'Sample Text') for analysis.\")\n",
        "            return\n",
        "\n",
        "        with st.spinner('Running NLP Pipeline (Classification, Summarization, Extraction)...'):\n",
        "            summary = run_summarization(full_text)\n",
        "            sections, petitioner = run_extraction_ner(full_text)\n",
        "            category = run_classification(full_text)\n",
        "            outcome = run_outcome_detection(full_text)\n",
        "            timeline_df = run_timeline_extraction(full_text)\n",
        "\n",
        "        st.success(\"Analysis Complete!\")\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        tab1, tab2, tab3, tab4 = st.tabs([\"üìÑ Case Brief & Outcome\", \"üß† NLP Model Insights\", \"üìÖ Chronology\", \"üìñ Full Text\"])\n",
        "\n",
        "        with tab1:\n",
        "            st.header(f\"Final Outcome (Obj 6): {outcome}\")\n",
        "            st.markdown(\"---\")\n",
        "            col1, col2 = st.columns(2)\n",
        "            col1.metric(\"Predicted Category (Obj 4: SVM Model)\", category)\n",
        "            col2.metric(\"Petitioner (Obj 2: Extraction)\", petitioner)\n",
        "            st.subheader(\"Summary (Objective 1: Abstractive Gen AI)\")\n",
        "            st.markdown(f\"> *{summary}*\")\n",
        "\n",
        "        with tab2:\n",
        "            st.subheader(\"Key Legal Sections Extracted (Objective 3: Custom NER/Regex)\")\n",
        "            if sections:\n",
        "                st.code(\" | \".join(sections), language='text')\n",
        "                st.markdown(\"*(Extracted instances of IPC, CrPC, Constitution articles, etc.)*\")\n",
        "            else:\n",
        "                st.info(\"No specific legal sections found in the text.\")\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "            st.subheader(\"Model Usage Breakdown\")\n",
        "            st.markdown(\"- **Classification (Obj 4):** Uses the **TF-IDF Vectorizer** (NLTK) and the **SVM Classifier** (scikit-learn) loaded from `pkl` files.\")\n",
        "            st.markdown(\"- **Summarization (Obj 1):** Uses a pre-trained **Transformer LLM** (e.g., T5/BART) for abstractive generation.\")\n",
        "            st.markdown(\"- **Timeline (Obj 7):** Uses an **Instruction-tuned LLM** to extract structured JSON data.\")\n",
        "\n",
        "        with tab3:\n",
        "            st.header(\"Chronological Timeline of Events (Objective 7)\")\n",
        "            st.markdown(\"This timeline is generated by prompting a powerful LLM to extract date/event pairs.\")\n",
        "            st.dataframe(timeline_df.set_index('Date'), use_container_width=True)\n",
        "\n",
        "        with tab4:\n",
        "            st.header(\"Raw Judgment Text\")\n",
        "            st.expander(\"Click to view full text\").markdown(full_text)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "YB_zz7xDBG-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat streamlit.log"
      ],
      "metadata": {
        "id": "iXybplUSGqeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean up any lingering processes and rerun the launch sequence\n",
        "!kill $(lsof -t -i:8501) 2>/dev/null\n",
        "\n"
      ],
      "metadata": {
        "id": "C_PXICTcBRpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Start Streamlit using nohup\n",
        "print(\"Starting Streamlit app with nohup...\")\n",
        "!nohup streamlit run app.py > streamlit.log 2>&1 &\n",
        "\n"
      ],
      "metadata": {
        "id": "uFeIQqBUIfgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wait a sufficient time\n",
        "import time\n",
        "time.sleep(10)\n",
        "print(\"Streamlit initialization complete.\")\n"
      ],
      "metadata": {
        "id": "M3DDA6nEIk46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Python tools\n",
        "!pip install streamlit pandas scikit-learn --quiet\n",
        "# Install ssh-client (required for serveo)\n",
        "!apt-get install ssh -y --quiet"
      ],
      "metadata": {
        "id": "Ew8tP_1PIsU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Clean up any lingering processes\n",
        "# !kill $(lsof -t -i:8501) 2>/dev/null\n",
        "\n",
        "# # 1. Start Streamlit using nohup\n",
        "# print(\"Starting Streamlit app with nohup...\")\n",
        "# !nohup streamlit run app.py > streamlit.log 2>&1 &\n",
        "\n",
        "# # Wait 10 seconds for Streamlit to initialize\n",
        "# import time\n",
        "# time.sleep(10)\n",
        "# print(\"Streamlit initialization complete.\")\n",
        "\n",
        "# # 2. Create a public tunnel using Serveo.net\n",
        "# # This creates a public URL that forwards traffic to port 8501.\n",
        "# print(\"\\n--- üåê Creating Public Tunnel (Serveo.net) ---\\n\")\n",
        "\n",
        "# # Use a specific subdomain (e.g., 'legalai') to get a clean URL,\n",
        "# # or remove '-R legalai:80:localhost:8501' to get a random one.\n",
        "# !ssh -o StrictHostKeyChecking=no -R legalai:80:localhost:8501 serveo.net"
      ],
      "metadata": {
        "id": "8b1MfiCiJGC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Cloudflare Tunnel CLI\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n",
        "!chmod +x cloudflared"
      ],
      "metadata": {
        "id": "hS71JZr2JZHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kill any lingering processes on port 8501\n",
        "!kill $(lsof -t -i:8501) 2>/dev/null\n",
        "\n",
        "# 1. Start Streamlit using nohup\n",
        "print(\"Starting Streamlit app with nohup...\")\n",
        "!nohup streamlit run app.py > streamlit.log 2>&1 &\n",
        "\n",
        "# Wait 10 seconds for Streamlit to initialize\n",
        "import time\n",
        "time.sleep(10)\n",
        "print(\"Streamlit initialization complete.\")\n",
        "\n",
        "# 2. Create the Cloudflare Tunnel\n",
        "print(\"\\n--- üåê Creating Public Tunnel (Cloudflared) ---\\n\")\n",
        "# This command creates a temporary tunnel and prints the URL.\n",
        "!./cloudflared tunnel --url http://localhost:8501"
      ],
      "metadata": {
        "id": "X7T6-JPDJboA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}